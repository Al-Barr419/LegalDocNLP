My friend Jesper Vaczy Kragh has recently published an excellent book on the history of lobotomy in Denmark. Lobotomy was a psychosurgical treatment for mental illness that became popular during the 1940s and 1950s. It involved the severing of connections in the prefrontal cortex of the brain.

As Jesper explains, lobotomy became an accepted psychiatric treatment in many countries, including Denmark, which may have had the highest rates of lobotomy per capita. But why did this surgical approach—now associated more with Halloween than psychiatry—become so popular?

The history of lobotomy
As Jesper Vaczy Kragh, Mical Raz, and the late Jack D. Pressman have written, psychiatrists were attracted to lobotomy out of a combination of desperation and hope. Psychiatrists during the early part of the 20th century had few remedies in their toolbox. The drugs that were available were not particularly effective and often came with nasty side effects. Psychoanalysis was becoming popular, but it was time-consuming, expensive, and some believed it was only effective with educated individuals from the upper classes. Occupational therapy was often used in asylums, but questions were raised about whether the real motive for its use was economic, not therapeutic.

Then, during the 1920s and 1930s, a series of radical treatments emerged. Malarial fever therapy, insulin shock therapy, cardiazol shock therapy, and electroshock therapy were quickly embraced by psychiatrists who wanted to do something for their patients and thought that such scientific innovations were the answer. Although all of these treatments could be dangerous and did result in fatalities, they were seen as being on the cutting edge of medical technology and were largely welcomed.

Then, in 1935, Portuguese neurologist Egas Moniz developed the lobotomy, eventually winning the Nobel Prize for his work. As a surgical technique, it differed markedly from these other radical treatments, but it also provided a glimmer of hope. Soon, patients presenting an array of symptoms were being given lobotomies in many countries. Although the precise reasons for the treatment in specific patients varied, it was often given to disruptive patients in asylums who made life difficult for both staff and other patients. It was also given more often to women than men.

One such woman was Rosemary Kennedy, the sister of John F. Kennedy, who was lobotomized in 1943 when she was just 23. Her surgeon was the American Walter Freeman, who later developed a quicker, transorbital lobotomy, in which an ice pick-like surgical instrument was inserted through the eye socket. Freeman popularized lobotomy in the USA and elsewhere, particularly in the UK and Scandinavia. Approximately 40,000 lobotomies were performed in the United States. Unfortunately for Kennedy, however, as with many other lobotomy patients, the procedure was unsuccessful and left her in an infantile state and in institutions for the rest of her life.

For some patients, the procedure appears to have helped in various ways. It did not "cure" patients, but it did, in some cases, make disruptive patients much more docile and easy to manage. While some were able to live outside the asylum afterward, many others were not. For still others, the impact was either negligible or faded away over time. Many side effects were also reported; most notably, seizures. And there were also fatalities, sometimes due to the surgery itself and sometimes afterward.

By the late 1950s, the procedure was ebbing in popularity, partly due to concerns about it, but also because of the emergence of new psychiatric medications, such as the antipsychotic chlorpromazine. By the 1970s, lobotomy had largely fallen out of use, though new techniques, such as deep brain stimulation, are being used today.

The story of lobotomy prompts new questions
So, how should we judge this procedure today? On the one hand, it is important to understand that psychiatrists of the period often despaired at their inability to help patients. Lobotomy and other radical treatments offered hope at a time when standards for experimenting on patients were much more liberal and when there was great faith in science to solve all the world's problems.

But on the other hand, we also see how what should have been used as an absolute last resort—if at all—was often employed relatively quickly and in patients who were quite young and did not consent to the procedure. The fact that so many more women were lobotomized than men also raises disturbing questions.

Finally, it is important to realize that, while we may dismiss lobotomy as barbaric today, people of the future may have questions about the way we treat mental illness today. The story of lobotomy should prompt us to ask ourselves questions about consent, side effects, how we prioritize different therapies, and how we conceptualize mental illness itself.